DONE
1) Created the function 'ipak.R' that groups together all the packages needed, checks if they are installed,
   installs them if needed and   loads them

2) Implement a function ('prodNA', part of the missForest package for imputation) that set a % of missing values (i.e., misValperc)
   in each dataset used by SuperLearner

3) Added the packages MICE, Amelia, missForest, Hmisc, mi for imputation.For now we are using missForest for testing
   (likely has the best performance) [see this website for reference
    http://www.analyticsvidhya.com/blog/2016/03/tutorial-powerful-packages-imputing-missing-values/)

4) Change the rescale function with scale (easier implementation)

5) Moved the imputation inside the SuperLearner loop (normalization is still outside the loop...thoughts?).
   Imputation performed with missForest.

6) Added the new ALS dataset to the DATA CBDA repository

TO DO

1) Allow for multiple options for imputation methods to be used.

2) Fix the labeling bug in the histogram plots (now the plots are with densities and not absolute counts)

3) Making the SL objects "lighter", so we don't need to save workspaces of many GBs
   if M=10K and more than 20-30 algorithm variants are used
   
4) Start to generate a list of wrappers to make the SL.library more comprehensive,
   and select one or two classes of prediction algorithms (e.g., glm, glmnet)
   to be expanded with many options with the wrappers

5) Need to apply CBDA algorithm with SuperLearner the ALS dataset, after cleaning and harmonization is performed.

6) Test the imputation methods by eliminating 20-30% of the observations randomly from the dataset
   and compare the results vs the whole dataset
