---
title: "CBDA_Knockoff"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Knockoff filter
This is a new variable selection procedure, which could controll the FDR in the statistical model when the number of obervations is larger than the number of features.  
    
### step 1: construct knockoffs  
The knockoff filtering method doubles the number of original features by introducing a null-feature $(\tilde{x}_j$) corresponding to each original feature $(x_j)$ in the design matrix X. These dummy (knockoff) variables serve as a “control group” that allows us to estimate the rate at which the regularized linear modeling generated false-positive results (i.e., a feature is declared statistically important, when in reality, it’s not, just like the knockoffs represent null-data).    
    
The knockoff variables are designed to   
1.   Preserve the correlation structure of the observed original (real) data, i.e., $\tilde{x}_j^T \tilde{x}_k =x_j^T x_k$, for all j,k.  
2.   Maintain the correlation between different original variables the same as those between knockoffs and distinct original features, i.e., $\tilde{x}_j^T x_k=x_j^T x_k$, for $j \neq k$.  
This the new (augmented) design matrix we use in the regularized linear model will be
$$[X \tilde{X}]=[x_1,x_2,\ldots,x_n,\tilde{x}_1,\tilde{x}_2,\ldots,\tilde{x}_n] \in R^{k \times (2n)}$$ 
    
Let $\Sigma =X^T X$ represent the Gram matrix of the original features. According to the conditions above, we could ensure that $\tilde{X}_T \tilde{X} = \Sigma$ as well. Then we define $X^T \tilde{X}= \Sigma - 2 \xi I_n$  
The dummy knockoff features are defined to satisfy the 2 conditions above and to enable the decomposition of the symmetrized augmented design matrix:
    $$[X \tilde{X}]^T [X \tilde{X}]= \begin{pmatrix} \Sigma & (\Sigma-2 \xi I_n) \\ (\Sigma-2 \xi I_n) & \Sigma \\ \end{pmatrix} $$
      
where the following definitions ensure the satisfaction of the two by-design conditions on the knockoffs above: $\Sigma =X^T X \sim \xi I_n$, is full rank, the knockoff features are derivatives of their real counterparts $\tilde{X}=X(I_n - 2\xi \Sigma)+UC$, the matrix $C^T C$ can be factorized using Cholesky decomposition into a lower triangular matrix (C) and its transpose $(C^T)$, and U is an orthonormal matrix $(U^T U=I)$ that is orthogonal to the original feature matrix $X (tr(U X^T )=0)$.   
    
### Calculate statsitics for each pair of original and knockoff variables
We apply the LASSO model, and $l_1$ norm penalized regression to eatimates the coefficients $\beta.$  
$$\tilde{\beta}(\lambda)=arg {min_b} {\frac{1}{2} \Vert y-(X \tilde{X}) b\Vert _2 ^2 + \lambda \Vert b _1} $$   
    
With this model, we could conclude that if variables $X_j$ enters the LASSO model early adn it does so before its knockoff copy $\tilde{X}_j$, then it means that this variable belongs to the model. Otherwise, it should not include to the model. Hence, we taking $Z_j$ to be the point $\lambda$ on the lasso path at which feature $X_j$ first enters the model,$Z_j = sup {\lambda : \tilde{\beta}_j(\lambda) \neq 0}.$ $Z_j$ is small for those null variables.  
  
We use the following test statistic is used to determine the significance of each of the n features in the design matrix X:  
$$ W_j= max (z_j,\tilde{z}_j).sgn(z_j-\tilde{z}_j),$$
    
### step 3: Calculate a data-dependent threshold frnthe statistics.
To assess the performance of the knockoff filtering test, we use the false discovery rate (FDR):  
$$\underbrace {FDR}_{\text{False Discovery Rate}}=\underbrace {E}_{Expectation}(\underbrace{\frac{\text{number of false positives}}{\text{total number of selected features}}}_{\text{False Discovery Proportion}})$$  
Letting q stands for the target FDR.  
There has one theorem makes sure that this method could control a quantity nearly equal to the FDR.  
*Therorem 1*. for any $q \in [0,1]$, the knockoff methods satisfies
$$E [\frac{\text{the number of} {j : \beta_j = 0 \text{and}  j \in \tilde{S}}}{\text{the number of }{j : j \in \tilde{S}}+ q^(-1) }] \le q$$
where the expectation is taken over the Gaussian noise z in the model,while treating X and $\tilde {X}$ are fixed.  
    

    
*Therorem 2*. for any $q \in [0,1]$, the knockoff+ methods satisfies
$$FDR= E [ \frac {\text{the number of } {j : \beta_j = 0 \texst{and} j \in \tilde{S}}{\text{the number of }{j : j \in \tilde{S} \lor 1}} ] \le q  $$
where the expectation is taken over the Gaussian noise z in the model,while treating X and $\tilde {X}$ are fixed.  
    
        
Thus, our algorithm involves the following steps:  
1.  Augment the design matrix by introducing het fake knockoff features  
2.  Fit in the regularized linear model and obtain the estimates    
$[\beta_1,\beta_2,\ldots,\beta_n,\tilde{\beta}_1,\tilde{\beta}_2,\ldots,\tilde{\beta}_n ]$ via LASSO  
3.  For each of the 2n features, $[x_1,x_2,\ldots,x_n,\tilde{x}_1,\tilde{x}_2,\ldots,\tilde{x}_n ]$, compute the statistical significance of their corresponding effect sizes (obtained in step 2) using parametric or non-parametric test for $H_o: \beta=0$ vs.$H_a: \beta \neq 0$  
4.	Use the $[\tilde{\beta}_1,\tilde{\beta}_2,\ldots,\tilde{\beta}_n]$, as proxies of the knockoff features $[\tilde{x}_1,\tilde{x}_2,\ldots,\tilde{x}_n]$, to identify real vs. stochastic effects (the knockoff features serve as control variables (null effects), relative to the default $\alpha =0.05$  
5.	Report the (real) features $[x_(j_1 ),x_(j_2 ),x_(j_3 ),\ldots,x_(j_m ) ]$ that represent pairs of significant $x_j$ and insignificant features, according to the $W_j$ statistics  
6.	This protocol guarantees that the expected false discovery rate for the reported features (step 5) would be within the predefined false positive rate $\alpha=0.05$  

```{r same_part, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load a session
#load("~/Documents/NIH-grant/SOCR/CBDA_v0.RData")
#load("~/Documents/NIH-grant/SOCR/CBDA_v2_temp.RData")

## STEP 1 - DATA CLEANING
## This is just an example with the MRI dataset "NeuroIm1.txt"
# Set the working directory for the R Code development
 setwd("~/Desktop/R")

## Retrieve the dataset (edit the directory where the dataset is located)
#NeuroIm1 = read.table("NeuroIm1.txt", header = TRUE)
NeuroIm1 = read.table("NeuroIm1.txt", header=TRUE,fill=TRUE)
#NeuroIm1 = read.delim("/home/simeonem/Documents/NIH-grant/SOCR/GITHUB/DATA/NeuroIm1.txt", header = TRUE)

# Set the list of packages/libraries to install/include (done through the ipak.R function) 
packages <- c("ggplot2", "plyr","dplyr", "colorspace","grid","data.table","VIM","MASS","Matrix",
              "lme4","arm","foreach","glmnet","class","nnet","mice","missForest",
              "calibrate","nnls","SuperLearner","plotrix","TeachingDemos","plotmo",
              "earth","parallel","splines","gam", "Amelia", "Hmisc", "mi","bart","svm","randomForest")
#source('~/Documents/NIH-grant/SOCR/GITHUB/ipak.R')

#source('ipak.R')
#ipak(packages)

# Delete the last 3 columns from the big matrix NeurIm1 ["ROI","Measure","Value"]
# and store the rest in a temp matrix, compressing unique values by patients
NeuroIm1_Fix <- unique(NeuroIm1[,-1*(11:13)])
#length(unique(NeurIm1_Fix))

# Define Variables/Columns: Patients, type of Measures and ROI [Region of Interest]
Patients <- NeuroIm1_Fix$Subject_ID
Measures <- c("SA","SI","CV","FD")
ROI <- unique(NeuroIm1$ROI)
# Initialize a new data matrix that has the correct # of columns
NeuroIm1_NEW = array(0, c(length(Patients), length(ROI)*length(Measures)))
## We assign names to the columns in the form of Value_Measure_ROI



# STEP 1
names = NULL
for (j in 1:length(Measures)) {
  for (i in 1:length(ROI))
    names = c(names, paste("Value",Measures[j], ROI[i],"END", sep="_"))
}
#length(names)
#dim(NeuroIm1_NEW)
names(NeuroIm1_NEW) <- names


# STEP 2 - DATA HARMONIZATION and STEP 3 DATA AGGREGATION
# This loops extract a record from the big dataset, matching patient id, type of measure and ROI.
# Then It looks at the columns of the expanded matrix (# columns = Measures x ROI), and selects
# the column that matches the label resulting by combining Measures and ROI values in the record.
# Then it retries the value in the Value field of the big matrix and place it in the expanded matrix
# at the selected column

for (i in 1:length(Patients)) {
  for (j in 1:length(Measures)) {
    for (s in 1:length(ROI)) {
      NeuroIm1_temp = NeuroIm1[NeuroIm1$Subject_ID==i & NeuroIm1$Measure==Measures[j] & NeuroIm1$ROI==ROI[s],]
      a = paste(c("Value_",Measures[j],"_",ROI[s],"_END"),collapse="")
      b = which(names(NeuroIm1_NEW)==a)
      NeuroIm1_NEW[i,b] <- NeuroIm1_temp$Value
    }
  }
}

# Appends the matrix that is fixed from the big matrix to the expanded one.
# The final dimension of this matrix is rows=# patients
# This is the matrix to use for the analysis with SuperLearner, after few more
# data cleaning and recasting.
# List of libraries/packages needed below

## Use ctrl+shift+C to comment/uncomment multiple lines
NeuroIm1_Final <- cbind(NeuroIm1_Fix, NeuroIm1_NEW)
# Set the names/labes of the columns
names(NeuroIm1_Final) <- c(names(NeuroIm1_Fix),names)


# DATA relabeling
# Recast the binary variable Sex
NeuroIm1_Final$Sex <- ifelse(NeuroIm1_Final$Sex=="F",1,0)

## Generating binary outcome matrices and relabeling categorical variables
## SINCE WE HAVE 3 GROUPS: AD-aLZHEIMER, MCI=MINOR COGNITIVE IMPAIRMENT, NC=NORMAL
NeuroIm1_Final_AD = NeuroIm1_Final[NeuroIm1_Final$Group == "AD",]
NeuroIm1_Final_NC = NeuroIm1_Final[NeuroIm1_Final$Group == "NC",]
NeuroIm1_Final_MCI = NeuroIm1_Final[NeuroIm1_Final$Group == "MCI",]

# Merge the datasets for training. I am defining 3 datsets here to be used for training
# since the SuperLearner function only works with binomial outcomes (for now).
# We will test SL comparing AD vs NC
NeuroIm1_Final_AD_vs_NC_training = rbind(NeuroIm1_Final_AD,NeuroIm1_Final_NC) # This is our aggregated dataset !!
NeuroIm1_Final_AD_vs_MCI_training = rbind(NeuroIm1_Final_AD,NeuroIm1_Final_MCI)
NeuroIm1_Final_NC_vs_MCI_training = rbind(NeuroIm1_Final_NC,NeuroIm1_Final_MCI)

# Labels the columns of the new matrices
names(NeuroIm1_Final_AD_vs_NC_training) <- c(names(NeuroIm1_Fix),names)
names(NeuroIm1_Final_AD_vs_MCI_training) <- c(names(NeuroIm1_Fix),names)
names(NeuroIm1_Final_NC_vs_MCI_training) <- c(names(NeuroIm1_Fix),names)

# Defining and recasting the binary variable Group for each dataset
NeuroIm1_Final_AD_vs_NC_training$Group <- ifelse(NeuroIm1_Final_AD_vs_NC_training$Group=="AD",1,0)
NeuroIm1_Final_AD_vs_MCI_training$Group <- ifelse(NeuroIm1_Final_AD_vs_MCI_training$Group=="AD",1,0)
NeuroIm1_Final_NC_vs_MCI_training$Group <- ifelse(NeuroIm1_Final_NC_vs_MCI_training$Group=="MCI",1,0)

# Define the temporary output [Ytemp] and input [Xtemp] matrices for the SuperLearner call
Xtemp = NeuroIm1_Final_AD_vs_NC_training; # temporary X-->Xtemp to modify and pass to SuperLearner
#Xtemp = NeuroIm1_Final_AD_vs_MCI_training; 
#Xtemp = NeuroIm1_Final_MCI_vs_NC_training; 
#Xnew = NeuroIm1_Final_AD_vs_NC_test; # temporary X-->Xtemp to modify and pass to SuperLearner

# Assign the Group column to the output Y
Ytemp = NeuroIm1_Final_AD_vs_NC_training$Group; # Output Matrix Y for SuperLearner
#Y = NeuroIm1_Final_AD_vs_MCI_training$Group; # Output Matrix Y for SuperLearner
#Y = NeuroIm1_Final_MCI_vs_NC_training$Group; # Output Matrix Y for SuperLearner

# Select the columns Patient ID [1], MMSE [3]  (Mini-Mental State Exam score, a cognitive assessment measure),
# and CDR [4] (Clinical Dementia Rating scale from the test dataset X) and [Group]
# and eliminate them from the training dataset because almost perfectly correlated to Y
w = which(names(NeuroIm1_Final_AD_vs_NC_training) == "Subject_ID" | names(NeuroIm1_Final_AD_vs_NC_training) == "Group" |
            names(NeuroIm1_Final_AD_vs_NC_training) == "MMSE" | names(NeuroIm1_Final_AD_vs_NC_training) == "CDR")
names(Xtemp)
Xtemp <- Xtemp[,-1*w] # Eliminate the output column (Group) from the training dataset X 
names(Xtemp)

for(i in 1:53){
  Ytemp[i]<-rnorm(1, mean=mean(Ytemp),sd=sd(Ytemp))
}
print(Ytemp)
Xnorm <- Xtemp # eliminate q patients for prediction [not used in the training]

Ytemp <- Ytemp # eliminate q patients for prediction [not used in the training]

names(Xnorm) <- names(Xtemp)
names(Xnorm)

```


```{r knockoff filter, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
## STEP 5 - Knockoff Filter 

library(knockoff)

M=50; # This is the number of random subsets of the big dataset [from 1e2 to 1e5] to perform SuperLearner on
coordSL=dim(Xnorm)
dim(Xnorm)
N=coordSL[1]
K=coordSL[2]

## knockoff filter
for(j in seq(1:M)) {
  Kcol <- round(K*runif(1,0.05,0.10)) # sample a value from a uniform distribution within 0.15 and 0.3 [number of columns/covariates between 15-30% of the big dataset]
  Nrow <- round(N*runif(1,0.8,1)) # sample a value from a uniform distribution within 0.6 and 0.8 [number of rows/subjects between 60-80% of the big dataset]
  #Nrow <- N # this option will NOT sample subjects/rows, it will include them all
  k <- sample(1:K,Kcol) # this is where I generate the sample of columns
  n <- sample(1:N,Nrow) # this is where I generate the sample of rows

  # Automated labeling of sub-matrices, assigned to X
  #eval(parse(text=paste0("X",j," <- as.data.frame(Xtemp[,k])")))
  #eval(parse(text=paste0("X",j," <- as.data.frame(dplyr::slice(X",j,",n))")))
  eval(parse(text=paste0("X",j," <- Xnorm[,k]")))
  #eval(parse(text=paste0("X",j," <- dplyr::slice(X",j,",n)")))
  eval(parse(text=paste0("X",j," <- X",j,"[n,]")))
  eval(parse(text=paste0("X <- X",j)))
  eval(parse(text=paste0("Y",j," <- Ytemp[n]")))
  eval(parse(text=paste0("Y <- Y",j)))

  eval(parse(text=paste0("k",j," <- k")))
  eval(parse(text=paste0("n",j," <- n")))
  
  # SUPERLEARNER-SL FUNCTION CALL that generates SL objects
  knockoff <- function (X, y, fdr) {
    y = Y
    X = X
    # Run the knockoff filter.
    result = knockoff.filter(X, y, fdr = fdr, knockoffs = 'equicorrelated')
    knockoff_selected = names(result$selected)
    print<-(knockoff_selected)
    list(Knockoff = knockoff_selected)
  }
  fdr = 0.50
  knockoff(X,y,fdr)
  
  results= lapply(Y, function(y) knockoff(X, y, fdr))


#for (j in 1:M)
#{
#  print(results[j][1])
#}
}
```